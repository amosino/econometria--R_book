[
["index.html", "Apuntes de Econometría Prólogo", " Apuntes de Econometría Aplicaciones con R Alejandro Mosiño 2017-10-23 Prólogo "],
["motivacion.html", "Capítulo 1 Motivación", " Capítulo 1 Motivación En lo que sigue, utilizaremos los datos alojados en la siguiente dirección: Para comenzar, considera los siguientes datos sobre la esperanza de vida y el ingreso per-cápita: data&lt;-read.csv(file.path(&quot;/Users&quot;,&quot;alejandro.mosino&quot;,&quot;Documents&quot;, &quot;github&quot;,&quot;econometria--R_book&quot;,&quot;_data_econometria&quot;,&quot;lif_exp4.csv&quot;), header=TRUE, sep=&quot;,&quot;) knitr::kable( data, caption = &#39;Datos sobre ingreso per-cápita y esperanza de vida para cuatro países seleccionados. Fuente: CIA World Factbook (2016).&#39;, booktabs = TRUE ) Tabla 1.1: Datos sobre ingreso per-cápita y esperanza de vida para cuatro países seleccionados. Fuente: CIA World Factbook (2016). country rgdp life_exp France 42400 77.2 Japan 38900 85.0 Mexico 18900 72.9 Nigeria 5900 81.8 De la Tabla 1.1 obtenemos la siguiente relación: with(data,plot(rgdp,life_exp, xlab=&quot;Ingreso per cápita&quot;, ylab=&quot;Esperanza de vida&quot;)) text(data$rgdp,data$life_exp,labels=data$country, pos=4) Figura 1.1: Relación entre el ingreso per cápita y la esperanza de vida para 4 países seleccionados Los países más ricos parecen tener una esperanza de vida más elevada. El país más pobre, Nigeria en nuestro ejemplo, tiene la esperanza más baja de los cuatro países considerados. Sin embargo, cuando tenemos tan pocos datos no es posible realizar inferencia alguna. Conviene entonces repetir el experimento utilizando más países. data_full&lt;-data&lt;-read.csv(file.path(&quot;/Users&quot;,&quot;alejandro.mosino&quot;,&quot;Documents&quot;, &quot;github&quot;,&quot;econometria--R_book&quot;,&quot;_data_econometria&quot;,&quot;lif_exp.csv&quot;), header=TRUE, sep=&quot;,&quot;) head(data_full) ## pais rgdp life_exp ## 1 Afghanistan 2000 51.3 ## 2 Albania 11900 78.3 ## 3 Algeria 15000 76.8 ## 4 American Samoa 13000 75.4 ## 5 Andorra 37200 82.8 ## 6 Angola 6800 56.0 with(data_full,plot(rgdp,life_exp,xlab=&quot;Ingreso per cápita&quot;, ylab=&quot;Esperanza de vida&quot;)) with(data_full,abline(lm(life_exp ~ rgdp))) Figura 1.2: Relación entre el ingreso per cápita y la esperanza de vida Como puede verse en la Figura 1.2, si utilizamos más datos la relación positiva entre el ingreso per cápita y la esperanza de vida se hace mucho más evidente. En la gráfica hemos incluido, además, una línea que nos permite representar esta relación. Nuestro objetivo es saber cómo trazarla. Dado que la relación entre el ingreso per cápita y la esperanza de vida parece ser lineal, un buen candidato para representarla matemáticamente es: \\[\\begin{equation} y_i = \\beta_1 + \\beta_2 x_i + u_i \\tag{1.1} \\end{equation}\\] donde \\(y_i\\) es la esperanza de vida (la variable en el eje de las “\\(y\\)”), \\(x_i\\) es el ingreso per cápita (la variable en el eje de las “\\(x\\)”) y \\(u_i\\) es un error, o ruido. Los coeficientes \\(\\beta_1\\) y \\(\\beta_2\\) son desconocidos, por lo que tienen que ser estimados. En la siguiente sección daremos más detalles sobre la relación entre las dos variables de la ecuación (1.1): \\(y_i\\) y \\(x_i\\). Además, estudiaremos el significado de los coeficientes \\(\\beta_1\\) y \\(\\beta_2\\), y aprenderemos cómo estimarlos. "],
["el-modelo-de-regresion-simple.html", "Capítulo 2 El modelo de regresión simple 2.1 Minimización de \\(\\sum_{i=1}^{N}e_i\\) 2.2 El método de los mínimos cuadrados ordinarios: introducción", " Capítulo 2 El modelo de regresión simple Nota que la fórmula para \\(y_i\\) que hemos aprendido (ecuación (1.1) de la sección anterior) tiene dos componentes: 1) parte no aleatoria y 2) parte aleatoria. La parte no aleatoria puede definirse como: \\[\\begin{equation} \\mathbb{E}(y_i | x_i) = \\beta_1 + \\beta_2 x_i. \\end{equation}\\] La fórmula anterior implica que, si conociéramos los valores de \\(\\beta_1\\) y \\(\\beta_2\\), la línea que estamos buscando partiría de \\(\\beta_1\\) y tendría pendiente \\(\\beta_2\\). Por otra parte, el componente aleatorio es \\(u_i\\). En otras palabras, \\(u_i\\) es un componente desconocido que no nos permite calcular con certeza los valores de \\(y_i\\) a partir de la ecuación (1.1). Pero, ¿porqué existe este \\(u_i\\)? La inclusión de \\(u_i\\) en el modelo se justifica por las siguientes razones: La posible omisión de variables explicativas. Una posible agregación incorrecta de variables. Una posible especificación incorrecta del modelo. La posible elección de una forma funcional incorrecta. Por posibles errores de medición. Lo anterior implica que, dado que no es posible encontrar la línea verdadera delimitada por \\(\\mathbb{E}(y_i)\\), esta tiene que ser aproximada. Esta aproximación resulta en la siguiente ecuación estimada: \\[\\begin{equation} \\widehat{y}_i= b_1 + b_2 x_i. \\end{equation}\\] Aunque esta línea podría bien trazarse a ojo de buen cubero, existen algunas técnicas formales, todas ellas involurando al residual de estimación. Este está definido como: \\[\\begin{align} e_i &amp;= y_i - \\widehat{y}_i \\\\ &amp;= y_i - b_1 - b_2 x_i \\tag{2.1} \\end{align}\\] Naturalmente, el objetivo es encontrar \\(b_1\\) y \\(b_2\\) tal que los valores de \\(e_i\\) sean los más bajos posibles. 2.1 Minimización de \\(\\sum_{i=1}^{N}e_i\\) Como primera opción para estimar los coeficientes de la ecuación (2.1), podríamos intentar resolver el siguiente problema: \\[\\begin{align} \\min_{b_1,b_2}\\sum_{i=1}^{N}e_i &amp;= \\min_{b_1,b_2}\\sum_{i=1}^{N}(y_i - \\widehat{y}_i)\\\\ &amp;= \\min_{b_1,b_2}\\sum_{i=1}^{N}(y_i - y_i - b_1 - b_2 x_i). \\end{align}\\] Sin embargo, notemos que si fijamos: \\[\\begin{align} b_1 &amp;= \\overline{y}=\\frac{1}{N} \\sum_{i=1}^{N} y_i\\\\ b_2 &amp;= 0, \\end{align}\\] obtenemos que: \\[\\begin{equation} \\sum_{i=1}^{N}e_i = 0, \\end{equation}\\] es decir, la suma de los residuales es cero (su valor mínimo) y: \\[\\begin{equation} \\widehat{y}_i = \\overline{y}. \\end{equation}\\] El resultado anterior implica que siempre podríamos obtener una línea horizontal sobre \\(\\overline{y}\\). Esto, naturalmente, no parece ser una buena aproximación, sean cuales sean los datos analizados. Para nuestro ejemplo de la esperanza de vida, esta aproximación resultaría en la siguiente línea de estimación y coeficientes: data_full&lt;-read.csv(file.path(&quot;/Users&quot;,&quot;alejandro.mosino&quot;,&quot;Documents&quot;,&quot;github&quot;,&quot;econometria--R_book&quot;,&quot;_data_econometria&quot;,&quot;lif_exp.csv&quot;), header=TRUE, sep=&quot;,&quot;) b1 &lt;- mean(data_full$life_exp) b2 &lt;- 0 with(data_full,plot(rgdp,life_exp,xlab=&quot;Ingreso per cápita&quot;, ylab=&quot;Esperanza de vida&quot;)) abline(a=b1, b=b2) print(paste0(&quot;El valor estimado b1 es: &quot;, b1)) ## [1] &quot;El valor estimado b1 es: 72.5152466367713&quot; print(paste0(&quot;El valor estimado b2 es: &quot;, b2)) ## [1] &quot;El valor estimado b2 es: 0&quot; Compara este resultado con el presentado en la sección anterior. ¿Cuál te parece mejor? 2.2 El método de los mínimos cuadrados ordinarios: introducción El resultado de la sección anterior puede mejorarse si, en lugar de minimizar la suma de los residuales, minimizamos la suma del cuadrado de los residuales (RSS por sus siglas en inglés). Este problema se conoce como el método de los mínimos cuadrados ordinarios (MCO u OLS por sus siglas en inglés), y requiere encontrar los estimadores \\(b_1\\) y \\(b_2\\) tales que: \\[\\begin{align} b_1 , b_2 &amp;= \\underset{b_1,b_2}{\\arg\\min}\\left\\{RSS\\right\\} \\\\ RSS&amp;= \\sum_{i=1}^N e_i^2. \\end{align}\\] Para ver el funcionamiento de este método, consideremos el siguiente ejemplo: x&lt;-c(1,2) y&lt;-c(3,5) yhat&lt;-c(&quot;$b_1+b_2$&quot;, &quot;$b_1+2b_2$&quot;) e&lt;-c(&quot;3-$b_1-b_2$&quot;, &quot;$5- b_1-2b_2$&quot;) lab&lt;-c(&quot;$x_i$&quot;, &quot;$y_i$&quot;, &quot;$yhat_i$&quot;, &quot;$e_i$&quot;) data_full&lt;-data.frame(x,y,yhat,e) names(data_full)&lt;-lab knitr::kable( data_full[,1:2], caption = &#39;Ejemplo: Mínimos cuadrados ordinarios. Dos observaciones.&#39;, booktabs = TRUE ) Tabla 2.1: Ejemplo: Mínimos cuadrados ordinarios. Dos observaciones. \\(x_i\\) \\(y_i\\) 1 3 2 5 Para encontrar los estimadores del método de los MCO, seguimos los siguientes pasos: Primero, calculamos \\(e_i\\). Recordemos que este está definido como \\(e_i=y_i-\\widehat{y}_i\\). Los cálculos se muestran en la siguiente tabla: knitr::kable( data_full, caption = &#39;Ejemplo: Mínimos cuadrados ordinarios. Cálculo del residual.&#39;, booktabs = TRUE ) Tabla 2.2: Ejemplo: Mínimos cuadrados ordinarios. Cálculo del residual. \\(x_i\\) \\(y_i\\) \\(yhat_i\\) \\(e_i\\) 1 3 \\(b_1+b_2\\) 3-\\(b_1-b_2\\) 2 5 \\(b_1+2b_2\\) \\(5- b_1-2b_2\\) Ahora podemos calcular el RSS. Este es: \\[\\begin{equation} RSS= (3-b_1-b_2)^2+(5-b_1-2b_2)^2 \\end{equation}\\] Minimizamos el \\(RSS\\) con respecto a \\(b_1\\) y \\(b_2\\). Las condiciones de primer orden resultan en el siguiente sistema de dos ecuaciones con dos incógnitas: \\[\\begin{align} 2b_1+3b_2-8&amp;=0\\\\ 3b_1+5b_2-13&amp;=0. \\end{align}\\] Ahora Resolvemos el sistema. Resulta muy fácil encontrar que: \\[\\begin{align} b_1 &amp;= 1\\\\ b_2 &amp;= 2. \\end{align}\\] Finalmente, estamos listos para trazar la línea estimada. Esta se ve como en la siguiente figura: with(data_full,plot(x,y, xlab=&quot;x&quot;, ylab=&quot;y&quot;)) with(data_full,abline(lm(y ~ x))) Figura 2.1: Solución por MCO. Datos ficticios Ejercicio ¿Cómo cambiaría el resultado anterior si agregamos un tercer punto con coordenadas \\((x_3,y_3)=(3,6)\\)? "]
]
